{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dados de nomes em Security Cards\n",
    "https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import bigquery\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# sql = \"\"\"\n",
    "# SELECT\n",
    "#   name,\n",
    "#   gender,\n",
    "#   COUNT(name) AS num_names\n",
    "# FROM\n",
    "#   `bigquery-public-data.usa_names.usa_1910_current`\n",
    "# GROUP BY\n",
    "#   name,\n",
    "#   gender\n",
    "# \"\"\"\n",
    "\n",
    "# names_df = client.query(sql).to_dataframe()\n",
    "\n",
    "# print(names_df.shape)\n",
    "# names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "import random\n",
    "\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    all_letters = string.ascii_letters + \" .,;'\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "MAX_CHAR = 4\n",
    "NEUTRAL_NAMES = False\n",
    "NAME_COUNT_THRESHOLD = 5\n",
    "\n",
    "model_df = pd.read_csv(\"data/bigquery-results/bq-results-20220101-122926-phn99u10bjpw.csv\")\n",
    "model_df['ascii_name'] = [unicodeToAscii(name) for name in model_df['name']]\n",
    "model_df['lowascii_name'] = model_df['ascii_name'].str.lower()\n",
    "\n",
    "model_df['bound_lowascii_name'] = (MAX_CHAR-1)*'_' + model_df['lowascii_name'] + '_'*(MAX_CHAR-1) #grande acrescimo a performance\n",
    "model_df['meta_bound_lowascii_name'] = model_df['bound_lowascii_name'] + ' ' + (MAX_CHAR-1)*'_' + model_df['bound_lowascii_name'].apply(lambda x: doublemetaphone(x)[0]) + '_'*(MAX_CHAR-1)\n",
    "\n",
    "#incorporating total_name_count to see possible neutral names and filtering\n",
    "model_df = model_df.merge(\n",
    "    model_df[['name','count_name']].rename(columns={'count_name':'name_total_count'}).groupby('name', as_index=False).sum(),\n",
    "    how='inner',on='name')\n",
    "model_df['perc_name_tc'] = 1 - (model_df['name_total_count'] - model_df['count_name'])/model_df['name_total_count']\n",
    "\n",
    "#filter for names\n",
    "model_df = model_df[model_df['name_total_count'] >= NAME_COUNT_THRESHOLD]\n",
    "\n",
    "if NEUTRAL_NAMES:\n",
    "    #creating neutral scores for names\n",
    "    model_df['neutral_score'] = - (model_df['perc_name_tc'] - 0.5)**2\n",
    "    model_df = model_df.sort_values(by='neutral_score', ascending=True)\n",
    "else:\n",
    "    model_df = model_df.sort_values(by='count_name',ascending=False).drop_duplicates(subset='name', keep='first')\n",
    "\n",
    "\n",
    "model_df = model_df.sample(len(model_df))\n",
    "\n",
    "# Step 2: Split Training and Test Data\n",
    "X = model_df.drop(['gender'],axis=1)\n",
    "y = np.asarray(model_df['gender'].values.tolist())\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 - Classical NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.90      0.90      0.90      2356\n",
      "           M       0.84      0.85      0.84      1522\n",
      "\n",
      "    accuracy                           0.88      3878\n",
      "   macro avg       0.87      0.87      0.87      3878\n",
      "weighted avg       0.88      0.88      0.88      3878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### import pandas as pd\n",
    "import enchant\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import CategoricalNB,BaseNB,BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "MAX_CHAR = 4\n",
    "\n",
    "X_train = X_train_df['lowascii_name']\n",
    "X_test = X_test_df['lowascii_name']\n",
    "\n",
    "vect = CountVectorizer(analyzer='char', ngram_range=(1,MAX_CHAR))\n",
    "#vect = grid_search.best_estimator_['vectorizer']\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "model = LinearSVC(dual=True)\n",
    "#model = grid_search.best_estimator_['model']\n",
    "\n",
    "model.fit(X_train_vect, y_train)\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2 - Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode to ASCII: Slusarski\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "tensor(35)\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def df2dict(df,key_col,val_col):\n",
    "    \n",
    "    final_dict = {}\n",
    "    for key in df[key_col].unique():\n",
    "        final_dict.update({key : df[df[key_col] == key][val_col].tolist()})\n",
    "        \n",
    "    return final_dict\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print('Unicode to ASCII:',unicodeToAscii('Ślusàrski'))\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "all_categories = ['F', 'M']\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "print(letterToTensor('J').argmax())\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharTensor:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "HiddenValue:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "\n",
      "\n",
      "CharTensor:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "HiddenValue:\n",
      " tensor([[-0.0804, -0.0111,  0.0399, -0.0793,  0.0201, -0.1030,  0.0663,  0.0238,\n",
      "         -0.0021,  0.0532,  0.0757, -0.0762,  0.0213, -0.0096,  0.0129,  0.0430,\n",
      "          0.0206, -0.0164,  0.0421, -0.0217,  0.0956,  0.0040,  0.0157,  0.0973,\n",
      "         -0.0065, -0.0324,  0.0967,  0.0051, -0.0110, -0.0316,  0.0294,  0.0185,\n",
      "         -0.0908, -0.0677,  0.0068, -0.0186, -0.0246, -0.0976, -0.0511, -0.0021,\n",
      "         -0.0111, -0.0099, -0.1168,  0.0581,  0.0289,  0.0489,  0.0928,  0.0603,\n",
      "         -0.0074,  0.0996,  0.0196, -0.0427,  0.0049, -0.0956, -0.0512, -0.1195,\n",
      "          0.0167, -0.0096, -0.0383, -0.0062, -0.0787,  0.0472,  0.0500,  0.0313,\n",
      "         -0.0300,  0.0220, -0.0254,  0.0016, -0.0046, -0.0962,  0.0322,  0.0011,\n",
      "         -0.0708, -0.0086, -0.0215, -0.0325, -0.0843,  0.0113, -0.0221, -0.0831,\n",
      "          0.0193,  0.0264, -0.1307, -0.0501,  0.0965, -0.0033,  0.0472,  0.0480,\n",
      "          0.0905, -0.0880,  0.1291,  0.0808, -0.0253,  0.0481,  0.1113, -0.0204,\n",
      "          0.0399, -0.0294,  0.0079,  0.0700, -0.1204, -0.0436, -0.0553, -0.0805,\n",
      "         -0.0754,  0.0235, -0.0147, -0.0356,  0.0869,  0.0326, -0.0134, -0.0050,\n",
      "          0.0100, -0.0924,  0.0121, -0.0551,  0.0165,  0.0413, -0.0417, -0.1261,\n",
      "          0.0096,  0.0551,  0.0510, -0.0598,  0.0452,  0.0862, -0.0176, -0.0190]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "\n",
      "CharTensor:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "HiddenValue:\n",
      " tensor([[-0.0936,  0.0201,  0.0146, -0.0222,  0.0947, -0.0837,  0.0630,  0.0413,\n",
      "          0.0403,  0.0270,  0.0970, -0.0061, -0.0185,  0.0632, -0.0182, -0.0018,\n",
      "         -0.0094, -0.1030, -0.0052,  0.0089,  0.1016,  0.0030,  0.0684,  0.0224,\n",
      "          0.0691, -0.0116,  0.1312, -0.0320, -0.1413, -0.1303, -0.0061,  0.0153,\n",
      "         -0.0124, -0.0372,  0.0240,  0.0267, -0.0460, -0.0516,  0.0434,  0.0925,\n",
      "         -0.0783, -0.0650, -0.0141,  0.1056,  0.0651, -0.0382,  0.0991,  0.0324,\n",
      "         -0.0660,  0.1194,  0.0025,  0.0043,  0.0039, -0.0734,  0.0655, -0.0230,\n",
      "         -0.0287,  0.0138,  0.0256,  0.1542, -0.0822,  0.0992,  0.0417, -0.0160,\n",
      "          0.0132, -0.0908,  0.0037,  0.0055, -0.0141,  0.0698,  0.0564,  0.0385,\n",
      "         -0.0391,  0.1364,  0.0621,  0.0438, -0.0158,  0.0261,  0.0598, -0.0917,\n",
      "          0.0534, -0.1028, -0.0520, -0.0440,  0.0186, -0.0017, -0.0340,  0.0813,\n",
      "          0.0142,  0.0555,  0.0138,  0.0594,  0.0347, -0.0326,  0.0942, -0.0059,\n",
      "          0.0294,  0.0507,  0.0125, -0.0506, -0.0315, -0.0461,  0.0095,  0.0658,\n",
      "          0.0618,  0.0470,  0.0900,  0.0025,  0.1139, -0.0164,  0.0843,  0.0059,\n",
      "         -0.0566,  0.0043,  0.0530, -0.0325,  0.0798,  0.0183, -0.0529, -0.0531,\n",
      "         -0.0957,  0.0793,  0.0781, -0.1177,  0.0338,  0.0638, -0.0143, -0.0355]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.7393, -0.6490]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor('tom')\n",
    "hidden = rnn.initHidden()\n",
    "\n",
    "for charTensor in input:\n",
    "    print('CharTensor:\\n',charTensor)\n",
    "    print('HiddenValue:\\n',hidden)\n",
    "    print('\\n'*2)\n",
    "    output, hidden = rnn(charTensor,hidden)\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = F / line = adi\n",
      "category = F / line = zola\n",
      "category = F / line = teena\n",
      "category = F / line = lucetta\n",
      "category = M / line = aedyn\n",
      "category = M / line = quinlan\n",
      "category = M / line = haakon\n",
      "category = M / line = keegan\n",
      "category = F / line = midge\n",
      "category = M / line = rozell\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([X_train_df.reset_index(drop=True), \n",
    "           pd.Series(y_train,name='gender')],axis=1)\n",
    "\n",
    "category_lines = df2dict(df=train_df, key_col='gender', val_col='lowascii_name')\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "def returnTrainingExample(idx, X=X_train.tolist(), y=y_train.tolist()):\n",
    "    \n",
    "    assert isinstance(X_train,(list,pd.Series))\n",
    "    category = y[idx]\n",
    "    line = X[idx]\n",
    "    line_tensor = lineToTensor(line)\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    return category, line, category_tensor, line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5% (0m 12s) 0.5801 maris / F ✓\n",
      "10000 10% (0m 24s) 0.4192 keilany / F ✓\n",
      "15000 15% (0m 38s) 0.5502 rashaud / M ✓\n",
      "\n",
      " ===== 1.0 Epoch Finished ============================== \n",
      "\n",
      "20000 20% (0m 57s) 0.8363 cove / F ✗ (M)\n",
      "25000 25% (1m 17s) 1.3106 yale / F ✗ (M)\n",
      "30000 30% (1m 34s) 0.2222 radha / F ✓\n",
      "\n",
      " ===== 2.0 Epoch Finished ============================== \n",
      "\n",
      "35000 35% (1m 50s) 0.0928 jaquita / F ✓\n",
      "40000 40% (2m 6s) 1.2956 isayah / F ✗ (M)\n",
      "45000 45% (2m 32s) 0.4595 marshae / F ✓\n",
      "\n",
      " ===== 3.0 Epoch Finished ============================== \n",
      "\n",
      "50000 50% (2m 49s) 0.3307 jaleah / F ✓\n",
      "55000 55% (3m 12s) 0.8071 cordie / M ✗ (F)\n",
      "60000 60% (3m 29s) 1.1623 jann / M ✗ (F)\n",
      "\n",
      " ===== 4.0 Epoch Finished ============================== \n",
      "\n",
      "65000 65% (3m 47s) 0.0554 kaitlynne / F ✓\n",
      "70000 70% (4m 7s) 0.9169 dashay / M ✗ (F)\n",
      "75000 75% (4m 22s) 0.3618 shiv / M ✓\n",
      "\n",
      " ===== 5.0 Epoch Finished ============================== \n",
      "\n",
      "80000 80% (4m 38s) 0.1251 tashaun / M ✓\n",
      "85000 85% (4m 52s) 0.1490 montavious / M ✓\n",
      "90000 90% (5m 7s) 1.7926 shilo / M ✗ (F)\n",
      "\n",
      " ===== 6.0 Epoch Finished ============================== \n",
      "\n",
      "95000 95% (5m 22s) 0.0428 zaila / F ✓\n",
      "100000 100% (5m 34s) 0.7073 lorry / M ✗ (F)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def train():\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.0010 # If you set this too high, it might explode. If too low, it might not learn\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 100\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    X=X_train.tolist()\n",
    "    y=y_train.tolist()\n",
    "    idx = iter % len(X)\n",
    "    category, line, category_tensor, line_tensor = returnTrainingExample(idx, X=X, y=y)\n",
    "    output, loss = train()\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "        \n",
    "    if iter % len(X_train)== 0:\n",
    "        print(f'\\n ===== {iter / len(X_train)} Epoch Finished','='*30,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2755ac9c400>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucas tensor([[-2.3903, -0.0961]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "print('Lucas', evaluate(lineToTensor('Lucas')))\n",
    "\n",
    "X=X_test.tolist()\n",
    "y=y_test.tolist()\n",
    "\n",
    "y_pred = []\n",
    "for idx in range(len(X)):\n",
    "    category, line, category_tensor, line_tensor = returnTrainingExample(idx, X=X, y=y)\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    y_pred.append(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.85      0.84      0.85      2356\n",
      "           M       0.76      0.78      0.77      1522\n",
      "\n",
      "    accuracy                           0.82      3878\n",
      "   macro avg       0.81      0.81      0.81      3878\n",
      "weighted avg       0.82      0.82      0.82      3878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 64\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size=len(all_letters), output_size=2):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-c4a0ef474259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtag_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
